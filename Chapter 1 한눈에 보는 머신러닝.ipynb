{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 머신러닝이란?\n",
    "\n",
    "> 머신러닝은 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다.\n",
    "\n",
    "_아서 사무엘 Arthur Samuel, 1959\n",
    "\n",
    "> 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.\n",
    "\n",
    "_톰 미첼 Tom Mitchell, 1997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 왜 머신러닝을 사용하는가?\n",
    "- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제\n",
    "- 전통 방식으로는 전혀 해결 방법이 없는 복잡한 문제\n",
    "- 유동적인 환경\n",
    "- 복잡한 문제와 대량의 데이터에서 통찰 얻기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 머신러닝 시스템의 종류\n",
    "\n",
    "- 사람의 감독 하에 훈련하는 것인지 / 그렇지 않은 것인지 (지도, 비지도, 준지도, 강화학습)\n",
    "- 실시간으로 진적인 학습을 하는지 아닌지 (온라인 학습과 배치학습)\n",
    "- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 훈련 데이터셋에서 과학자들처럼 패턴을 발견하여 예측 모델을 만드는지 (사례 기반 학습과 모델 기반 학습)\n",
    "\n",
    "이 범주들은 서로 배타적이지 않습니다.\n",
    "\n",
    "https://stickie.tistory.com/m/43\n",
    "\n",
    "http://solarisailab.com/archives/1785\n",
    "\n",
    "https://mangkyu.tistory.com/m/32\n",
    "\n",
    "위키백과: [비지도 학습](https://ko.m.wikipedia.org/wiki/비지도_학습), [지도 학습](https://ko.m.wikipedia.org/wiki/지도_학습), [강화 학습](https://ko.m.wikipedia.org/wiki/강화_학습), [준지도 학습](https://ko.m.wikipedia.org/wiki/준_지도_학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 배치학습과 온라인학습\n",
    "\n",
    "#### 배치 학습\n",
    "\n",
    "가용한 데이터를 모두 사용해 훈련. 시간과 자원을 많이 소모하므로 보통 오프라인에서 수행. 시스템을 훈련시킨 다음 제품 시스템에 적용하면 더 이상의 학습 없이 실행됩니다.\n",
    "\n",
    "새로운 데이터에 대해 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련해야 합니다. 그런 다음 이전 시스템을 중지시키고 새 시스템으로 교체합니다.\n",
    "\n",
    "전체 과정을 자동화 하여 대처한다.\n",
    "\n",
    "\n",
    "장점\n",
    "- 간단하며 적용이 쉽다.\n",
    "\n",
    "단점\n",
    "- 전체 데이터 셋을 사용해 훈련하는데 몇 시간이 소요될 수 있다. 보통 24시간마다, 또는 매주 시스템을 훈련\n",
    "- 컴퓨팅 자원이 많이 소모된다. (CPU, 메모리 공간, 디스크 공간, 디스크IO, 네트워크IO 등). 데이터가 대량인 경우 문제\n",
    "- 자원이 제한된 시스템(임베디드 또는 화성 탐사 로버 등)에서 문제\n",
    "\n",
    "#### 온라인 학습\n",
    "\n",
    "\n",
    "장점\n",
    "- 빠른 변화에 적응하는 시스템에 적합\n",
    "- 컴퓨팅 자원이 제한된 경우, 아주 큰 데이터셋을 학습할 때 유용\n",
    "\n",
    "학습률 learning rate\n",
    "- ㅍ은 경우: 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림.\n",
    "- 낮은 경우: 관성이 커져 느리게 학습된다. 하지만 새로운 데이터에 있는 잡음에 덜 민감해 진다.\n",
    "\n",
    "단점\n",
    "- 나쁜 데이터가 주입될 때 시스템 성능이 점진적으로 감소된다. 악의적 공격을 막기 위해 시스템을 면밀히 모니터링하고 성능 감소가 감지되면 즉각 학습을 중지시켜야 한다. 이상치 탐지 알고리즘 등을 사용해서 비정상 데이터를 잡아낼 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 instance-based learning, model-based learning\n",
    "\n",
    "선형회귀 알고리즘, theta0, theta1 파라미터를 조정한다. 데이터에 가장 잘 맞는 파라미터를 찾는다. \n",
    "\n",
    "모델이 얼마나 좋은지 측정: utility function 또는 fitness function을 정의\n",
    "\n",
    "모델이 얼마나 나쁜지 측정: cost function을 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 머신러닝의 주요 도전 과제\n",
    "\n",
    "품질을 떨어트리는 두 가지 요인\n",
    "- 나쁜 알고리즘\n",
    "- 나쁜 데이터\n",
    "\n",
    "나쁜 데이터\n",
    "- 충분하지 않은 양의 훈련 데이터\n",
    "- 대표성 없는 훈련 데이터: sampling bias가 발생할 수 있다.\n",
    "- 낮은 품질의 데이터: error, outlier, noise 가 많은 데이터로 훈련한다면 패턴을 찾기 어려워 잘 작동하지 않는다. 데이터 정제에 많은 시간을 투자하자.\n",
    "- 관련 없는 특성: garbage in, garbage out. 좋은 특성을 찾는다. 특성공학 feature engineering이라 한다.\n",
    "  - 특성 선택 feature selection\n",
    "  - 특성 추출 feature extraction: 특성을 결합한다. 차원축소 알고리즘 등이 이에 해당한다.\n",
    "  - 새로운 데이터를 수집, 새 특성을 만든다.\n",
    "  \n",
    "나쁜 알고리즘\n",
    "- 훈련 데이터 과대적합: overfitting. 규제 regularization이 중요하다. 이를 하이퍼파라미터 hyperparameter가 결정한다. 하이퍼 파라미터 튜닝은 매우 중요한 과정이다.\n",
    "  - 모델에 제한을 가한다. 특성의 개수를 줄인다. 고차원 다항모델보다 선형 모델에 가까운 것을 선택한다.\n",
    "  - 훈련 데이터를 더 많이 모은다.\n",
    "  - error, outlier, noise를 줄인다.\n",
    "- 훈련 데이터 과소적합: underfitting. 모델이 너무 단순해서 발생.\n",
    "  - 파라미터가 더 많은 강력한 모델을 선택\n",
    "  - 더 좋은 특성을 제공한다. (특성 엔지니어링)\n",
    "  - 모델의 제약을 줄인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 테스트와 검증\n",
    "\n",
    "훈련 세트, 검증 세트 validation set, 테스트 세트\n",
    "\n",
    "교차 검증 기법 cross-validation\n",
    "\n",
    "https://3months.tistory.com/118\n",
    "\n",
    "https://datascienceschool.net/view-notebook/266d699d748847b3a3aa7b9805b846ae/\n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Training,_validation,_and_test_sets\n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 연습문제\n",
    "\n",
    "1. 머신러닝을 어떻게 정의할 수 있나요?\n",
    "\n",
    "명시적인 프로그래밍 없이 컴퓨터가 학습할 수 있는 능력을 갖추게 하는 기술\n",
    "\n",
    "작업 T에 대한 컴퓨터의 성능 P가 경험 E에 의해 성능이 향상되었다면, 성능 향상분을 머신러닝에 의한 학습으로 정의할 수 있다.\n",
    "\n",
    "2. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해 보세요.\n",
    "\n",
    "기존 방식으로 해결할 때 너무 많은 규칙이나 조정이 필요한 경우\n",
    "\n",
    "기존 방식으로 해결할 방법이 없는 복잡한 경우\n",
    "\n",
    "유동적인 환경\n",
    "\n",
    "복잡하고 다양한 데이터에서 새로운 규칙을 찾으려는 경우\n",
    "\n",
    "3. 레이블된 훈련 세트란 무엇인가요?\n",
    "\n",
    "지도 학습에서 training data에 특성feature과 함께 원하는 답label이 포함되어 있는 데이터 세트\n",
    "\n",
    "4. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?\n",
    "\n",
    "분류와 회귀\n",
    "\n",
    "분류classification - 카테고리를 예측\n",
    "\n",
    "회귀regression - 값을 예측\n",
    "\n",
    "5. 보편적인 비지도 학습 네 가지는 무엇인가요?\n",
    "\n",
    "군집clustering, 시각화visualization, 차원축소dimensionality reduction, 연관규칙학습assiciation rule learning\n",
    "\n",
    "군집 - 데이터를 특정 개수 또는 임의의 개수의 그룹으로 분류하는 기법\n",
    "\n",
    "시각화 - 도식화, 이해를 도와 예상하지 못한 패턴을 발견하는 데 도움을 준다.\n",
    "\n",
    "차원축소 - feature selection, feature extraction 등을 통해 실행속도향상 또는 예측 성능 향상을 도모한다.\n",
    "\n",
    "연관규칙학습 - 데이터간 흥미로운 관계를 찾는다\n",
    "\n",
    "6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?\n",
    "\n",
    "강화학습reinforcement learning\n",
    "\n",
    "행동을 실행하고 그 결과로 reward나 penalty를 얻어서 가장 큰 reward를 얻는 policy를 스스로 학습하는 알고리즘\n",
    "\n",
    "7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?\n",
    "\n",
    "레이블된 데이터셋이 있는 경우: 분류classification\n",
    "\n",
    "없는 경우: 군집clustering\n",
    "\n",
    "8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?\n",
    "\n",
    "스팸인지 아닌지 라는 label이 주어진 지도 학습에 해당한다.\n",
    "\n",
    "9. 배치학습 시스템과 온라인 학습 시스템이 무엇인가요?\n",
    "\n",
    "배치학습은 시스템을 완전히 훈련시킨 후 실제 배포 환경에서는 더 이상 학습하지 않는 시스템을 말한다.\n",
    "\n",
    "온라인 학습은 실제 환경에서 순차적으로 한개씩, 또는 미니배치로 주입된 데이터를 통해 연속적으로 학습하는 시스템이다.\n",
    "\n",
    "10. 외부 메모리 학습이 무엇인가요?\n",
    "\n",
    "전체 데이터셋이 메모리 공간에 모두 올라갈 수 없는 경우 데이터를 미니배치로 쪼개어 점진적 단계적으로 학습하는 시스템\n",
    "\n",
    "11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?\n",
    "\n",
    "사례 기반 학습 instance-based learning\n",
    "\n",
    "12. 모델 파라미터와 학습 알고리즘의 하이퍼 파라미터 사이에는 어떤 차이가 있나요?\n",
    "\n",
    "모델 파라미터 - 학습 데이터셋을 겪으면서 조정되며 최적화 되는 파라미터. 알고리즘이 최적 값을 찾는 파라미터\n",
    "\n",
    "하이퍼 팔ㅏ미터 - 사용자가 직접 주입하고 튜닝하는 파라미터. 반복횟수, 규제, learning rate 등. 알고리즘 자체의 파라미터\n",
    "\n",
    "13. 모델 기반 학습 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?\n",
    "\n",
    "일반화가 잘 되어 최상의 성능을 내는 최적화된 모델 파라미터를 찾는 것이 목표. \n",
    "\n",
    "효용함수 또는 비용함수를 정의하여 훈련 데이터를 공급하여 비용함수를 최소화하는 모델을 만들도록 시스템을 훈련. \n",
    "\n",
    "새로운 샘플을 주입해 예측, 추론.\n",
    "\n",
    "14. 머신러닝의 주요 도전 과제는 무엇인가요?\n",
    "\n",
    "나쁜 데이터, 나쁜 알고리즘 의 문제가 있다.\n",
    "\n",
    "나쁜 데이터 - 적은 데이터, error, outlier, noise가 많은 저품질의 데이터셋, sampling bias가 심한 대표성 없는 데이터셋, 관련 없는 feature가 많은 데이터셋\n",
    "\n",
    "나쁜 알고리즘 - 과대적합, 과소적합\n",
    "\n",
    "15. 모델이 훈련데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책은 무엇인가요?\n",
    "\n",
    "오버피팅을 의미. 더 많은 데이터셋을 모으거나, 모델을 단순화하거나, 데이터 정제를 해야 한다.\n",
    "\n",
    "16. 테스트 세트가 무엇이고 왜 사용해야 하나요?\n",
    "\n",
    "새로운 샘플을 주입하기 위해 별도로 준비한 데이터세트. 모델이 새로운 샘플에 대해 만들 일반화 오차를 추정하기 위해 사용한다.\n",
    "\n",
    "17. 검증 세트의 목적은 무엇인가요?\n",
    "\n",
    "모델을 비교하는데 사용한다. 이를 통해 모델을 선택하고 하이퍼파라미터를 튜닝한다.\n",
    "\n",
    "18. 테스트 세트를 사용해 하이퍼 파라미터를 튜닝하면 어떤 문제가 생기나요?\n",
    "\n",
    "테스트 데이터에 오버피팅이 될 가능성이 있고 일반화 오차가 낙관적으로 측정되어 실제 런치이 시 성능이 떨어질 수 있다.\n",
    "\n",
    "19. 교차 검증이 무엇이고, 왜 하나의 검증 세트보다 선호하나요?\n",
    "\n",
    "훈련 세트를 여러 subset으로 나누고 나머지 부분을 validation set으로 사용하는 기법, 검증세트를 별도로 나누지 않고 훈련세트만으로 모델을 비교할 수 있다. 훈련 데이터를 최대한ㅇ로 활용할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
